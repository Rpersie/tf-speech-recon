[arch-parameters] 
arch = single_fc
is_adversarial = 0



[vocabulary]
#Words to use (others will be added to an unknown label)
wanted_words = yes,no,up,down,left,right,on,off,stop,go

[data-processing-parameters]
#Which features (mfcc, spectrogram, raw signal) should be used to train the model.
features = mfcc

#Window size for FFT
fft_window_size = 256

#How loud the background noise should be, between 0 and 1.
background_volume = 0.4

#How many of the training samples have background noise mixed in.
background_frequency = 0.9

#How much of the training data should be silence.
silence_percentage = 10.0

#How much of the training data should be unknown words.
unknown_percentage = 10.0

#Range to randomly shift the training audio by in time.Range to randomly shift the training audio by in time.
time_shift_ms = 100.0

#What percentage of wavs to use as a test set.
testing_percentage = 10

#What percentage of wavs to use as a validation set.
validation_percentage = 1

#Expected sample rate of the wavs.
sample_rate = 16000

#Expected duration in milliseconds of the wavs.
clip_duration_ms = 1000

#How long each spectrogram timeslice is.
window_size_ms = 30

#How long each spectrogram timeslice is
window_stride_ms = 10

#How many bins to use for the MFCC fingerprint.
dct_coefficient_count = 40


[train-parameters]
#How many training loops to run.
how_many_training_steps = 20000, 5000, 5000

#How large a learning rate to use when training.
learning_rate = 0.001, 0.0001, 0.00001

#How many items to train with at once
batch_size = 10

#How often to evaluate the training results.
eval_step_interval = 50

#Save model checkpoint every save_steps.
save_step_interval = 500



