[arch-parameters]
arch = ds_cnn
model_size_info = 6, 276, 10, 4, 2, 1, 276, 3, 3, 2, 2, 276, 3, 3, 1, 1, 276, 3, 3, 1, 1, 276, 3, 3, 1, 1, 276, 3, 3, 1, 1

[vocabulary]
#Words to use (others will be added to an unknown label)
wanted_words = yes,no,up,down,left,right,on,off,stop,go

[data-processing-parameters]
#Which features (mfcc, spectrogram, raw signal) should be used to train the model.
features = mfcc

#Window size for FFT
fft_window_size = 256

#How loud the background noise should be, between 0 and 1.
background_volume = 0.2

#How many of the training samples have background noise mixed in.
background_frequency = 0.8

#How much of the training data should be silence.
silence_percentage = 10.0

#How much of the training data should be unknown words.
unknown_percentage = 10.0

#Range to randomly shift the training audio by in time.Range to randomly shift the training audio by in time.
time_shift_ms = 100.0

#What percentage of wavs to use as a test set.
testing_percentage = 10

#What percentage of wavs to use as a validation set.
validation_percentage = 10

#Expected sample rate of the wavs.
sample_rate = 16000

#Expected duration in milliseconds of the wavs.
clip_duration_ms = 1000

#How long each spectrogram timeslice is.
window_size_ms = 40

#How long each spectrogram timeslice is
window_stride_ms = 20

#How many bins to use for the MFCC fingerprint.
dct_coefficient_count = 10


[train-parameters]
#How many training loops to run.
how_many_training_steps = 10000, 10000, 10000

#How large a learning rate to use when training.
learning_rate = 0.0005, 0.0001, 0.00002

#How many items to train with at once
batch_size = 100

#How often to evaluate the training results.
eval_step_interval = 200

#Save model checkpoint every save_steps.
save_step_interval = 500



